---
title: "Project 4"
author: "Omotayo Abdul-Hakeem"
date: "2/27/2020"
output: html_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(arsenal)
library(kableExtra)
library(pacman)
library(randomForest)
library(gbm)
library(pROC)
```

```{r a, echo=FALSE}

bank0 = read.csv("bank-additional-full.csv", sep=";")
# Remove duration variable
bank0 = select(bank0, -duration)
# Recode response as boolean
bank0$y = bank0$y == "yes"
bank0$y %>% table() %>% prop.table()
# For reordering and binning the months
month.list = c("mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec")
bank0$month = factor(bank0$month, levels=month.list)
hi_months = c("apr", "dec", "mar", "oct", "sep")
# Big line for creating our new dataset
bank = bank0 %>% 
  mutate(
    # Categorize into high and low months
    month.cat = 
      ifelse(month %in% hi_months, "high", "low"),
    # Recode "yes" defaults as "unknowns" because there were only 3 yes's 
        default = 
      ifelse(default=="yes", "unknown", "no"),
    age = age - mean(age),
    age_sq = age^2) %>% 
  # Drop variables that are redundant/unnecessary
  select(-pdays, -previous)
bank[bank$marital=="unknown","marital"] = "single"
#bank$group = ifelse(bank$y == 1, "Subscribed", "Not subscribed")
full.formula = formula(y ~ age + I(age^2) + job + education + default + housing +
                          contact + month + day_of_week + campaign + poutcome + emp.var.rate +
                         cons.price.idx + cons.conf.idx + euribor3m + nr.employed + marital)
red.formula = formula(y ~ age + I(age^2) + contact + month + day_of_week + campaign +
                        poutcome + emp.var.rate + cons.price.idx + cons.conf.idx +
                        nr.employed)
red.formula2 = formula(y ~ poutcome + job + nr.employed + euribor3m)


proper=function(x) paste0(toupper(substr(x, 1, 1)), tolower(substring(x, 2)))
bank$job = proper(bank$job)
bank$education = proper(bank$education)
bank$default = proper(bank$default)
bank$housing = proper(bank$housing)
bank$loan = proper(bank$loan)
bank$contact = proper(bank$contact)
bank$day_of_week = proper(bank$day_of_week)
bank$month = proper(bank$month)
bank$poutcome = proper(bank$poutcome)
bank$marital = proper(bank$marital)
col_name <-  c("job", "marital","education", "default","housing","loan","day_of_week","month","poutcome","y", "contact")
bank = bank %>% select(-month.cat)
bank[col_name] <- lapply(bank[col_name], factor)
labels(bank)  <- c(job = 'Job category',
                   education = 'Education',
                   default = 'Credit in default',
                   housing = 'Housing loan',
                   loan = 'Personal loan',
                   contact = 'Contact type',
                   month = 'Last contact month',
                   day_of_week = 'Last contact day of week',
                   campaign = 'Number of contact for client',
                   poutcome = 'Outcome of previous contact',
                   emp.var.rate = 'Employment variation rate ',
                   cons.price.idx = 'Consumer price index',
                   cons.conf.idx = 'Consumer confidence index',
                   euribor3m = 'Euribor 3 month rate',
                   nr.employed = 'Nmber of employees',
                   marital = 'Marital status')

# Training and test set
set.seed(123)
# bank = bank %>% select(-group)

bank <- bank %>% mutate(id = row_number())
trainSet =  bank %>% sample_frac(0.7)
testSet = anti_join(bank, trainSet, by = 'id')
trainSet <- trainSet %>% select(-c("id"))
testSet <- testSet %>% select(-c("id"))

##################################
# Logistic model
# --- Full model
fit_full <- glm(full.formula, data = trainSet, family = "binomial")
summary(fit_full)
full_probs = predict(object = fit_full, newdata = testSet, type="response")
# full_preds = rep("Pred No", length(full_probs))
# full_preds[full_probs > .5] = "Pred Yes"
# full_tab = table(full_preds, testSet$y)
# --- Reduced model
fit_red <- glm(red.formula, data = trainSet, family = "binomial")
summary(fit_red)
red_probs = predict(object = fit_red, newdata = testSet, type="response")
# red_preds = rep("Pred No", length(red_probs))
# red_preds[red_probs > .5] = "Pred Yes"
# red_tab = table(red_preds, testSet$y)
# --- Reduced model2
fit_red2 <- glm(red.formula2, data = trainSet, family = "binomial")
summary(fit_red2)
red_probs2 = predict(object = fit_red2, newdata = testSet, type="response")
# red_preds2 = rep("Pred No", length(red_probs2))
# red_preds2[red_probs2 > .5] = "Pred Yes"
# red_tab2 = table(red_preds2, testSet$y)


##################################
# Random forest

rf.full <- randomForest(full.formula, data = trainSet)
predicted.full <- predict(rf.full, newdata = testSet %>% select(-"y"))
observed.full <- testSet[,"y"]
rand_full_tab = table(predicted.full, observed.full)
rf.red <- randomForest(red.formula, data = trainSet)
predicted.red <- predict(rf.red, newdata = testSet %>% select(-"y"))
observed.red <- testSet[,"y"]
rand_red_tab = table(predicted.red, observed.red )
rf.red2 <- randomForest(red.formula2, data = trainSet)
predicted.red2 <- predict(rf.red2, newdata = testSet %>% select(-"y"))
observed.red2 <- testSet[,"y"]
rand_red_tab2 = table(predicted.red2, observed.red2)


##################################
# AdaBoost
# Full Adaboost 
trainSet$y <- unclass(trainSet$y) - 1
testSet$y <- unclass(testSet$y) - 1
boost.full = gbm(full.formula,
                 data = trainSet, distribution = "adaboost", n.trees = 10000)
boost.full.pred = predict(boost.full, testSet, n.trees = 10000, type = 'response')
# cutoff = 0.2
# boost.full.pred = boost.full.pred > cutoff
# boost.full.pred = ifelse(boost.full.pred, "Pred Yes", "Pred No")
# boost.full.tab = table(boost.full.pred, testSet$y)
# AIC Adaboost
boost.aic = gbm(red.formula,
                data = trainSet, distribution = "adaboost", n.trees = 10000)
boost.aic.pred = predict(boost.aic, testSet, n.trees = 10000, type = 'response')
# cutoff = 0.2
# boost.aic.pred = boost.aic.pred > cutoff
# boost.aic.pred = ifelse(boost.aic.pred, "Pred Yes", "Pred No")
# boost.aic.tab = table(boost.aic.pred, testSet$y)
# RFE Adaboost
boost.rfe = gbm(red.formula2,
                data = trainSet, distribution = "adaboost", n.trees = 10000)
boost.rfe.pred = predict(boost.rfe, testSet, n.trees = 10000, type = 'response')
# cutoff = 0.2
# boost.rfe.pred = boost.rfe.pred > cutoff
# boost.rfe.pred = ifelse(boost.rfe.pred, "Pred Yes", "Pred No")
# boost.rfe.tab = table(boost.rfe.pred, testSet$y)


# ------
# Function to calculate stats from tables
# calc_table_stats = function(tab, name="") {
#   concord = sum(tab[c(1,4)]) / sum(tab)
#   sens = tab[4] / sum(tab[3:4])
#   spec = tab[1] / sum(tab[1:2])
#   ppv = tab[4] / sum(tab[c(4,2)])
#   npv = tab[1] / sum(tab[c(1,3)])
#   results = list("Name"=name, "Concordance"=concord, "Sensitivity"=sens, "Specificity"=spec, "PPV"=ppv, "NPV"=npv)
#   return(results)
# }
# tab0 = rbind(calc_table_stats(full_tab, name="Logistic (Full)"),
#              calc_table_stats(rand_full_tab, name="Random Forest (Full)"),
#              calc_table_stats(boost.full.tab, name="AdaBoost (Full)"),
#              calc_table_stats(red_tab, name="Logistic (AIC)"),
#              calc_table_stats(rand_red_tab, name="Random Forest (AIC)"),
#              calc_table_stats(boost.aic.tab, name="AdaBoost (AIC)"),
#              calc_table_stats(red_tab2, name="Logistic (RFE)"),
#              calc_table_stats(rand_red_tab2, name="Random Forest (RFE)"),
#              calc_table_stats(boost.rfe.tab, name="AdaBoost (RFE)"))
# View(data.frame(tab0))
```

```{r roc}

## Full formular

plot.new()
par(mfrow = c(1,1))
par(pty = "s")
full_log <- roc(response = testSet$y, predictor = as.numeric(full_probs), plot = TRUE, legacy.axes = TRUE, percent = TRUE, xlab = "False Positive", ylab = "True Positive", print.auc = TRUE)

full_RF <- roc(response = testSet$y, predictor = as.numeric(predicted.full), plot = TRUE, legacy.axes = TRUE, percent = TRUE, xlab = "False Positive", ylab = "True Positive", print.auc = TRUE)

full_ADB <- roc(response = testSet$y, predictor = boost.full.pred, plot = TRUE, legacy.axes = TRUE, percent = TRUE, xlab = "False Positive", ylab = "True Positive", print.auc = TRUE)
par(pty = "s")
plot(full_ADB, col = "red")
lines(full_log, add = TRUE, col = "blue")
lines(full_RF, add = TRUE, col = "green")

# plot(full_log, add = TRUE, col = "blue")
# plot(full_RF, add = TRUE, col = "green")

##Reduced AIC

plot.new()
par(mfrow = c(1,1))
par(pty = "s")
red1_log <- roc(response = testSet$y, predictor = as.numeric(red_probs), plot = TRUE, legacy.axes = TRUE, percent = TRUE, xlab = "False Positive", ylab = "True Positive", print.auc = TRUE)

red1_RF <- roc(response = testSet$y, predictor = as.numeric(predicted.red), plot = TRUE, legacy.axes = TRUE, percent = TRUE, xlab = "False Positive", ylab = "True Positive", print.auc = TRUE)

red1_ADB <-roc(response = testSet$y, predictor = boost.aic.pred, plot = TRUE, legacy.axes = TRUE, percent = TRUE, xlab = "False Positive", ylab = "True Positive", print.auc = TRUE)

plot(red1_ADB, col = "red")
lines(red1_log,  col = "blue")
lines(red1_RF, col = "green")
## Reduced RFE

plot.new()

red2_log <- roc(response = testSet$y, predictor = red_probs2, plot = TRUE, legacy.axes = TRUE, xlab = "False Positive", ylab = "True Positive", print.auc = TRUE)

red2_RF <- roc(response = testSet$y, predictor = as.numeric(predicted.red2), plot = TRUE, legacy.axes = TRUE, xlab = "False Positive", ylab = "True Positive", print.auc = TRUE)

red2_ADB <- roc(response = testSet$y, predictor = as.numeric(boost.rfe.pred), plot = TRUE, legacy.axes = TRUE, xlab = "False Positive", ylab = "True Positive", print.auc = TRUE)
par(mfrow = c(1,1))
par(pty = "s")
plot(red2_ADB, col = "red")
lines(red2_log, col = "blue")
lines(red2_RF, col = "green")
```